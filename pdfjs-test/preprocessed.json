[
    {
        "title": "1 Introduction",
        "noOfSentences": 34,
        "text": "code repositories. Reading and trying to understand otherpeople’s code in such repositories is a difficult and unpleas-ant process for many software developers, especially whenthe code is not sufficiently commented. For example, if theJava method in Fig. 1 does not have the comment in the be-ginning, it will take the programmer quite some efforts tograsp the meaning of the code. However, with a meaning-ful sentence such as “calculates dot product of two points”as a descriptive comment, programmer’s productivity can betremendously improved.Figure 1: source code exampleA related scenario happens when one wants to search fora piece of code with a specific functionality or meaning. Or-dinary keyword search would not work because expressionsin programs can be quite different from natural languages.If methods are annotated with meaningful natural languagecomments, then keyword matching or even fuzzy semanticsearch can be achieved.Even though comments are so useful, programmers arenot using them enough in their coding. Table 1 shows thenumber of methods in ten actively developed Java reposito-ries from Github, and those of which annotated with a de-scriptive comment. On average, only 15.4% of the methodsare commented.To automatically generate descriptive comments fromsource code, one needs a way of accurately representing thesemantics of code blocks. One potential solution is to treateach code block as a document and represent it by a topicdistribution using models such as LDA (Blei, Ng, and Jor-dan 2003). However, topic models, when applied to sourcecode, have several limitations:•a topic model treats documents as a bag of words and ig-nores the structural information such as programming lan-guage syntax and function or method calls in the code;•the contribution of lexical semantics to the meaning ofcode is exaggerated;•comments produced can only be words but not phrases orsentences.One step toward generating readable comments is to usetemplates (McBurney and McMillan 2014; Sridhara et al.2010). The disadvantage is that comments created by tem-plates are often very similar to each other and only rele-vant to parts of the code that fit the template. For example,the comment generated by McBurney’s model for Fig. 1 isfairly useless:“This method handles the ccp dot and returnsa float. ccpDot() seems less important than average becauseit is not called by any methods.”To overcome these problems, in this paper, we propose touse Recursive Neural Network (RNN) (Socher et al. 2011a;2011b) to combine the semantic and structural informationfrom code. Recursive NN has previously been applied toparse trees of natural language sentences, such as the ex-ample of two sentences in Fig. 2. In our problem, sourcecodes can be accurately parsed into their parse trees, so re-cursive NN can be applied in our work readily. To this end,we design a new recursive NN called Code-RNN to extractthe features from the source code.Table 1: Ten Active Projects on GithubFigure 2: The Recursive Neural Networks of Two SentencesUsing Code-RNN to train from the source code, we canget a vector representation of each code block and this vec-tor contains rich semantics of the code block, just like wordvectors (Mikolov et al. 2013). We then use a Recurrent Neu-ral Network to learn to generate meaningful comments. Ex-isting recurrent NN does not take good advantage of thecode block representation vectors. Thus we propose a newGRU (Cho et al. 2014) cell that does a better job.In sum, this paper makes the following contributions:•by designing a new Recursive Neural Network,Code-RNN, we are able to describe thestructural informationof source code;•with the new design of a GRU cell, namelyCode-GRU,we make the best out of code block representation vectorto effectively generate comments for source codes;•theoverallframeworkachievesremarkableaccuracy(Rouge-2 value) in the task of generating descriptive com-ments for Java methods, compared to state-of-the-art ap-proaches."
    },
    {
        "title": "2 Framework",
        "noOfSentences": 77,
        "text": "sent source code and how to use the representation vectorof source code to generate comments.We propose a new kind of recursive neural network calledCode-RNN to encapsulate the critical structural informa-tion of the source code. Code-RNN is an arbitrary tree formwhile other recursive neural nets used in NLP are typicallybinary trees. Fig. 3 shows an example of Code-RNN for asmall piece of Java code.In Code-RNN, every parse tree of a program is encodedinto a neural network, where the structure of the networkis exactly the parse tree itself and each syntactic node inthe parse tree is represented by a vector representation.One unique internal node “CombineName” indicates a com-pound identifier that is the concatenation of several primi-tive words, for example, “allFound” can be split into “all”and “found”. More on the semantics of identifier will be dis-cussed later in this section.There are two models for the Code-RNN, namelySumModelandAverage Model:1. Sum ModelV=V+f(W×∑V+b)(1)2. Average ModelV=V+f(W×1n∑V+b)(2)HereVis the vector representation of sub-tree rooted atN;Vis the vector that represents the syntactic type ofNitself, e.g.,IfStatement;Cis the set of all child nodes ofN;Vis the vector that represents a subtree rooted atc, one ofN’s children. During the training,Wandbare tuned.V,VandVare calculated based on the structure of neuralnetwork.fisRELUactivation function.Theseequationsareappliedrecursively,bottom-upthrough the Code-RNN at every internal node, to obtain thevector representation of the root node, which is also the vec-tor of the entire code piece.Identifier SemanticsIn this work, we adopt two ways toextract the semantics from the identifiers. One is to split allthe long forms to multiple words and the other one is to re-cover the full words from abbreviations.Table 2 shows some example identifiers and the resultsof splitting. Many identifiers in the source code are combi-nation of English words, with the first letter of the word inupper case, or joined together using underscores. We thusdefine simple rules to extract the original English words ac-cordingly. These words are further connected by the “Com-bineName” node in the code-RNN.Table 3 shows some abbreviations and their intendedmeaning. We can infer the full-versions by looking forsource codeCode-RNNFigure 3: Code-RNN Examplelonger forms in the context of the identifier in the code.Specifically, we compare the identifier with the word listgenerated from the context of the identifier to see whetherthe identifier’s name is a substring of some word from thelist, or is the combination of the initial of the words in thelist. If the list contains only one word, we just check if theidentifier is part of that word. If so, we conclude that theidentifier is the abbreviation of that word with higher prob-ability. If the list contains multiple words, we can collect allthe initials of the words in the list to see whether the iden-tifier is part of this collection. Suppose the code fragmentisWe search for the original words of “dm” as follows. Since“dm” is not the substring of any word in the context, we col-lect the initials of the contextual words in a list: “m” “dm”and “cm”. Therefore, “dm” is an abbreviation of “Dou-bleMatrix”.Table 2: Example of Split IdentifiersTable 3: Example of AbbreviationTrainingEach source code block in the training data hasa class label. Our objective function is:whereVis the representation vector of source code,Vis an one-hot vector to represent the class label.Wandbare parameters for softmax function and will be tuned duringtraining. We use AdaGrad (Duchi, Hazan, and Singer 2011)to apply unique learning rate to each parameter.Existing work (Elman 1990; Sutskever, Martens, and Hin-ton 2011; Mikolov et al. 2010) has used Recurrent NeuralNetwork to generate sentences. However, one challenge toutilize the code block representation vector in Recurrent NNis that we can not feed the code block representation vectorto the Recurrent NN cell directly. We thus propose a vari-ation of the GRU based RNN. Fig. 4 shows our commentgeneration process.Figure 4: Comment GenerationWe use pre-trained model Code-RNN to get the represen-tation vector of the input code blockV. This vectorVis fixed during training of comment generation model. Thenwe feed code block vector into the RNN (Recurrent NeuralNetwork) model at every step. For example in Fig. 4, we in-put the START token as the initial input of model and feedthe code block vector into the hidden layer. After calculatingthe output of this step, we do the back-propagation. Then atstep two, we input the word “gets” and feed the code blockvectorVinto hidden layer again, and receive thehfromthe step one. We repeat the above process to tune all param-eters. The equations of comment generation model are listedbelow.z=σ(W·[h, x])(4)r=σ(W·[h, x])(5)c=σ(W·[h, x])(6) ̃h=tanh(W·[r∗h, c∗V, x])(7)h= (1−z)∗h+z∗ ̃h(8)y=sof tmax(Wh+b)(9)whereVis the code block representation vector,histhe previous state andxis the input word of this step.To better use the code block vectors, our model differsfrom existing RNNs, particularly in the definition ofcinthe Equation 6 and 7. The new RNN cell, illustrated in Fig.5, aims to strengthen the effect of code block vectors. Thismodified GRU is hereinafter calledCode-GRU. Code blockvector contains all information of code block but not all in-formation is useful at all steps. Therefore, we add a new gatecalled choose gate to determine which dimension of codeblock vector would work in Code-GRU. In Fig 5, the leftgate is the choose gate, and the other two gates are the sameas the original GRU.Figure 5: Structure of Code-GRUDuring test time, we input the “START” token at first andchoose the most probable word as the output. Then fromthe second step the input words of every step are the outputwords of previous one step until the output is “END” token.So that we can get an automatically generated comment forcode blocks in our model.To gain better results, we also apply the beam searchwhile testing. We adopt a variant of beam search with alength penalty described in (Wu et al. 2016). In this beamsearch model, there are two parameters: beam size andweight for the length penalty. We tune these two parame-ters on the validation set to determine which values to use.Our tuning ranges are:•beam size: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]•weight for the length penalty: [0, 0.1, 0.2, 0.3, 0.4, 0.5,0.6, 0.7, 0.8, 0.9, 1.0]"
    },
    {
        "title": "3 Evaluation",
        "noOfSentences": 75,
        "text": "uate Code-RNN model’s ability to classify different sourcecode blocks intokknown categories. In the second part, weshow the effectiveness of our comment generation modelby comparing with several state-of-the-art approaches inboth quantitative and qualitative assessments. The sourcecode of our approach as well as all data set is available athttps://adapt.seiee.sjtu.edu.cn/CodeComment/.Data SetThe goal is to classify a given Java method (weonly use the body block without name and parameters) intoa predefined set of classes depending on its functionality.Our data set comes from the Google Code Jam contest(2008∼2016), which there are multiple problems, each as-sociated with a number of correct solutions contributed byprogrammers.Each solution is a Java method. The set ofsolutions for the same problem are considered to functionidentically and belong to the same class in this work. Weuse the solutions (10,724 methods) of 6 problems as trainingset and the solutions (30 methods) of the other 6 problemsas the test set. Notice that the problems in the training dataand the ones in the test data do not overlap. We specificallydesign the data set this way because, many methods for thesame problem tend to use the same or similar set of identi-fiers, which is not true in real world application. The detailsof training set and test set are shown in Table 4.Table 4: Data Sets for Source Code ClusteringBaselinesWe compare Code-RNN with two baseline ap-proaches. The first one is called language embedding (LE)and only treats the source code as a sequence of words, mi-nus the special symbols (e.g., “$”, “(”, “+”,· · ·). All con-catenated words are preprocessed into primitive words aspreviously discussed. Then the whole code can be repre-sented by either the sum (LES) or the average (LEA) of wordvectors of this sequence, trained in this model.This approachbasically focuses on the word semantics only and ignores thestructural information from the source code.The second baseline is a variant of Code-RNN, whichpreprocesses the code parse tree by consistently replacingthe identifier names with placeholders before computing theoverall representation of the tree. This variant focuses on thestructural properties only and ignores the word semantics.Result of ClassificationAt test time, when a method isclassified into a class label, we need to determine which testproblem this class label refers to. To that end, we computethe accuracy of classification for all possible class label as-signment and use the highest accuracy as the one given by amodel.Table 5 shows the purity of the produced classes, the F1and accuracy of the 6-class classification problem by differ-ent methods. It is clear that Code-RNN (avg) perform betteruniformly than the baselines that use only word semanticsor only structural information. Therefore, in the rest of thissection, we will use Code-RNN(avg) model to create vectorrepresentation for a given method to be used for commentgeneration. The F1 score for each individual problem is alsoincluded in Table 6.Table 5: Purity, Average F1 and AccuracyTable 6: F1 scores of individual problemsData SetWe use ten open-source Java code repositoriesfrom GitHub for this experiment (see Table 1). In each ofthese repositories we extract descriptive comment and thecorresponding method pairs. Constructor methods are ex-cluded from this exercise. These pairs are then used for train-ing and test. Notice that all the method names and parame-ters are excluded from training and test.BaselinesWe compare our approach with four baselinemethods.•Mosesis a statistical machine translation system. We re-gard the source codes as the source language and the com-ments as the target, and use Moses to translate from thesource to the target.•CODE-NN(Iyer et al. 2016) is the first model to use neu-ral network to create sentences for source code. In thismodel author used LSTM and attention mechanism togenerate sentences. The original data set for CODE-NNare StackOverFlow thread title and code snippet pairs..In this experiment, we use the comment-code pair data inplace of the title-snippet data.•We apply thesequence-to-sequence (seq2seq)model usedin machine translation (Britz et al. 2017) and treat thecode as a sequence of words and the comment as anothersequence.•A. Karpathy and L. Fei-Fei (Karpathy and Fei-Fei 2015)proposed a meaningful method to generate image de-scriptions. It also used Recurrent NN and representationvector, so we apply this method to comment generationmodel. The main equations are:b=WV(10)h=f(Wx+Wh+b+b)(11)y=sof tmax(Wh+b)(12)whereW,W,W,W,xandb,bare parametersto be learned, andVis the method vector. We call thismodelBasic RNN.Moses and CODE-NN has its own terminate condition.Seq2Seq, Basic RNN and our model run 800 epochs duringtraining time. For one project, we separate the commentedmethods into three parts: training set, validation set and testset. We tune the hyper parameter on the validation set. Theresults of ten repositories are shown in Table 7.Evaluation MetricWe evaluate the quality of commentgeneration by the Rouge method(Lin 2004). Rouge modelcounts the number of overlapping units between generatedsentence and target sentence. We choose Rouge-2 score inthis paper where word based 2-grams are used as the unit,as it is the most commonly used in evaluating automatic textgeneration such as summarization.Table 7: Rouge-2 Values for Different MethodsExamples of Generated CommentFig. 6 shows the com-ments generated by the competing methods for three exam-ple Java methods coming from different repositories. Be-cause we delete all punctuation from the training data, thegenerated comments are without punctuation. Nonetheless,we can see that comments by our Code-GRU model are gen-erally more readable and meaningful.Figure 6: Examples of generated comments and corresponding code snippetsIn the first example, we can see that CODE-NN, Seq2Seqand Basic RNN’s results are poor and have almost nothingto do with the Gold comment. Even though both MOSESproduces a sequence of words that look similar to the Goldin the beginning, the rest of the result is less readable anddoes not have any useful information. For example, “if thelock state matches the given” is output repeatedly. MOSESalso produces strange terms such as “wbit” and “runit” justbecause they appeared in the source code. In the contrast,Code-GRU’s result is more readable and meaningful.In the second example, there is not any useful word inthe method body so the results of MOSES, CODE-NN andSeq2Seq are bad. Code-RNN can extract the structural in-formation of source code and embed it into a vector, so bothmodels that use this vector, namely Basic RNN and Code-GRU, can generate the relevant comments.In the third example, although all results change the typeof the value, that is, Basic RNN changes “int” to “char”while Code-GRU changes to “long”. “long” and “int” areboth numerical types while “char” is not. Thus Code-GRU isbetter than Basic RNN. For the result of Seq2Seq, although“float” is also a numerical type, it is for real numbers, andnot integers."
    },
    {
        "title": "4 Related Work",
        "noOfSentences": 47,
        "text": "popular in recent years. Existing work in source code min-ing include code search, clone detection, software evolution,models of software development processes, bug localization,software bug prediction, code summarization and so on. Ourwork can be categorized as code summarization and com-ment generation.Sridhara et al. (Sridhara et al. 2010) proposed an au-tomatic comment generator that identifies the content forthe summary and generates natural language text that sum-marizes the methods overall actions based on some tem-plates. Moreno et al. (Moreno et al. 2013) also proposed atemplate based method but it is used on summarizing Javaclasses. McBurney and McMillan (McBurney and McMil-lan 2014) presented a novel approach for automatically gen-erating summaries of Java methods that summarize the con-text surrounding a method, rather than details from theinternals of the method. These summarization techniques(Murphy 1996; Sridhara, Pollock, and Vijay-Shanker 2011;Moreno et al. 2013; Haiduc et al. 2010) work by select-ing a subset of the statements and keywords from the code,and then including information from those statements andkeywords in the summary. To improve them, Rodeghero etal. (Rodeghero et al. 2014) presented an eye-tracking studyof programmers during source code summarization, a toolfor selecting keywords based on the findings of the eye-tracking study.These models are invariably based on templates and care-ful selection of fragments of the input source code. In con-trast, our model is based on learning and neural network.There are also some models that apply learning methods tomine source code.Movshovitz-Attias and Cohen (Movshovitz-Attias andCohen 2013) predicted comments using topic models andn-grams. Like source code summarization, Allamanis etal. (Allamanis et al. 2015) proposed a continuous embed-ding model to suggest accurate method and class names.Iyer et al. (Iyer et al. 2016) proposed a new model calledCODE-NN that uses Long Short Term Memory (LSTM)networks with attention to produce sentences that can de-scribe C# code snippets and SQL queries. Iyer et al.’s workhas strong performance on two tasks, code summarizationand code retrieval. This work is very similar to our work, inthat we both use the Recurrent NN to generate sentencesfor source code. What differs is that we propose a newtype of Recurrent NN. Adrian et al. (Kuhn, Ducasse, andG ́ırba 2007) utilized the information of identifier names andcomments to mine topic of source code repositories. Punya-murthula (Punyamurthula 2015) used call graphs to extractthe metadata and dependency information from the sourcecode and used this information to analyze the source codeand get its topics.In other related domains of source code mining, codesearch is a popular research direction. Most search en-gines solve the problem by keyword extraction and signa-ture matching. Maarek et al. (Maarek, Berry, and Kaiser1991) used keywords extracted from man pages written innatural language and their work is an early example of ap-proaches based on keywords. Rollins and Wing (Rollins andWing 1991) proposed an approach to find code with the sig-natures present in code. Mitchell (Mitchell 2008) combinedsignature matching with keyword matching. Then Garcia etal. (Garcia-Contreras, Morales, and Hermenegildo 2016) fo-cused on querying for semantic characteristics of code andproposed a new approach which combines semantic charac-teristics and keyword matching.Cai(Cai2016)proposedamethodforcodeparal-lelization through sequential code search. That methodcanalsobeusedforclonedetection.WilliamsandHollingsworth(WilliamsandHollingsworth2005)de-scribed a method to use the source code change history ofa software project to drive and help to refine the searchfor bugs. Adhiselvam et al. (Adhiselvam, Kirubakaran, andSukumar 2015) used MRTBA algorithm to localize bug tohelp programmers debug. The method proposed in this papercan also benefit natural language search for code fragments."
    },
    {
        "title": "5 Conclusion",
        "noOfSentences": 7,
        "text": "work calledCode-RNNto extract the topic or function ofthe source code. This new Recursive Neural Network is theparse tree of the source code and we go through all the treefrom leaf nodes to root node to get the final representationvector. Then we use this vector to classify the source codeinto some classes according to the function, and classifica-tion results are acceptable. We further propose a new kindof GRU calledCode-GRUto utilize the vector created fromCode-RNN to generate comments. We apply Code-GRU toten source code repositories and gain the best result in mostprojects. This frame work can also be applied to other pro-gramming languages as long as we have access to the parsetree of the input program.As future work, we can add call graphs into our model,so that Code-RNN can contain invocation information andextract more topics from source code."
    },
    {
        "title": "Acknowledgement",
        "noOfSentences": 3,
        "text": "workwassupportedbyOracle-SJTUJointRe-search Scheme, NSFC Grant No. 9164620571421002 and61373031, and SJTU funding project 16JCCS08. HongfeiHu contributed to the identifier semantics part of the work."
    },
    {
        "title": "References",
        "noOfSentences": 248,
        "text": "Adhiselvam, A.; Kirubakaran, E.; and Sukumar, R.2015.An enhanced approach for software bug localization usingmap reduce technique based apriori (mrtba) algorithm.In-dian Journal of Science and Technology8(35).Allamanis, M.; Barr, E. T.; Bird, C.; and Sutton, C.2015.Suggesting accurate method and class names. InESEC/FSE,38–49. ACM.Blei, D. M.; Ng, A. Y.; and Jordan, M. I.2003.Latentdirichlet allocation.Journal of machine Learning research3(Jan):993–1022.Britz, D.; Goldie, A.; Luong, T.; and Le, Q.2017.Mas-sive Exploration of Neural Machine Translation Architec-tures.ArXiv e-prints.Cai, B. 2016. Code parallelization through sequential codesearch. InICSE-C, 695–697. ACM.Cho, K.; Van Merri ̈enboer, B.; Bahdanau, D.; and Ben-gio, Y.2014.On the properties of neural machinetranslation: Encoder-decoder approaches.arXiv preprintarXiv:1409.1259.Duchi, J.; Hazan, E.; and Singer, Y. 2011. Adaptive subgra-dient methods for online learning and stochastic optimiza-tion.Journal of Machine Learning Research12(Jul):2121–2159.Elman, J. L.1990.Finding structure in time.Cognitivescience14(2):179–211.Garcia-Contreras, I.; Morales, J. F.; and Hermenegildo,M. V.2016.Semantic code browsing.arXiv preprintarXiv:1608.02565.Haiduc, S.; Aponte, J.; Moreno, L.; and Marcus, A. 2010.On the use of automated text summarization techniques forsummarizing source code. InWCRE, 35–44. IEEE.Iyer, S.; Konstas, I.; Cheung, A.; and Zettlemoyer, L. 2016.Summarizing source code using a neural attention model. InACL, 2073–2083.Karpathy, A., and Fei-Fei, L. 2015. Deep visual-semanticalignments for generating image descriptions. InProceed-ings of the IEEE Conference on Computer Vision and Pat-tern Recognition, 3128–3137.Kuhn, A.; Ducasse, S.; and G ́ırba, T. 2007. Semantic clus-tering: Identifying topics in source code.Information andSoftware Technology49(3):230–243.Lin, C.-Y.2004.Rouge: A package for automatic evalu-ation of summaries.InText summarization branches out:Proceedings of the ACL-04 workshop, volume 8. Barcelona,Spain.Maarek, Y. S.; Berry, D. M.; and Kaiser, G. E. 1991. An in-formation retrieval approach for automatically constructingsoftware libraries.IEEE Transactions on software Engineer-ing17(8):800–813.McBurney, P. W., and McMillan, C. 2014. Automatic doc-umentation generation via source code summarization ofmethod context. InICPC, 279–290. ACM.Mikolov, T.; Karafi ́at, M.; Burget, L.; Cernock`y, J.; and Khu-danpur, S. 2010. Recurrent neural network based languagemodel. InInterspeech, volume 2, 3.Mikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; andDean, J.2013.Distributed representations of words andphrases and their compositionality.InAdvances in neuralinformation processing systems, 3111–3119.Mitchell, N. 2008. Hoogle overview.The Monad. Reader12:27–35.Moreno, L.; Aponte, J.; Sridhara, G.; Marcus, A.; Pollock,L.; and Vijay-Shanker, K.2013.Automatic generation ofnatural language summaries for java classes. InICPC, 23–32. IEEE.Movshovitz-Attias, D., and Cohen, W. W.2013.Naturallanguage models for predicting programming comments.Murphy, G. C. 1996.Lightweight structural summarizationas an aid to software evolution. Ph.D. Dissertation.Punyamurthula, S.2015.Dynamic model generation andsemantic search for open source projects using big data an-alytics.Ph.D. Dissertation, Faculty of the University OfMissouri-Kansas City in partial fulfillment Of the require-ments for the degree MASTER OF SCIENCE By SRAVANIPUNYAMURTHULA B. Tech, Jawaharlal Nehru Techno-logical University.Rodeghero, P.; McMillan, C.; McBurney, P. W.; Bosch, N.;and D’Mello, S.2014.Improving automated source codesummarization via an eye-tracking study of programmers.InICSE, 390–401. ACM.Rollins, E. J., and Wing, J. M. 1991. Specifications as searchkeys for software libraries. InICLP, 173–187. Citeseer.Socher, R.; Lin, C. C.; Manning, C.; and Ng, A. Y. 2011a.Parsing natural scenes and natural language with recursiveneural networks. InICML, 129–136.Socher, R.; Pennington, J.; Huang, E. H.; Ng, A. Y.; andManning, C. D. 2011b. Semi-supervised recursive autoen-coders for predicting sentiment distributions.InEMNLP,151–161. Association for Computational Linguistics.Sridhara, G.; Hill, E.; Muppaneni, D.; Pollock, L.; andVijay-Shanker, K.2010.Towards automatically generat-ing summary comments for java methods. InASE, 43–52.ACM.Sridhara, G.; Pollock, L.; and Vijay-Shanker, K. 2011. Gen-erating parameter comments and integrating with methodsummaries. InICPC, 71–80. IEEE.Sutskever, I.; Martens, J.; and Hinton, G. E. 2011. Gener-ating text with recurrent neural networks. InICML, 1017–1024.Williams, C. C., and Hollingsworth, J. K. 2005. Automaticmining of source code repositories to improve bug findingtechniques.IEEE Transactions on Software Engineering31(6):466–480.Wu, Y.; Schuster, M.; Chen, Z.; Le, Q. V.; Norouzi, M.;Macherey, W.; Krikun, M.; Cao, Y.; Gao, Q.; Macherey, K.;et al.2016.Google’s neural machine translation system:Bridging the gap between human and machine translation.arXiv preprint arXiv:1609.08144."
    }
]